{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基礎統計量の算出\n",
    "analysis.ipynbで作成済みのファイルを利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文書数、延べ語数、異なり語数\n",
    "import pandas as pd\n",
    "def count(file):\n",
    "    df = pd.read_csv(file, sep='\\t')\n",
    "    row_count = df.shape[0] # 文書数\n",
    "    token_sum = df['token'].sum()\n",
    "    type_sum = df['type'].sum()\n",
    "    return row_count, token_sum, type_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain A MT:  7 6070 1979\n",
      "domain B MT:  13 18444 5021\n",
      "domain C MT:  26 37291 9279\n",
      "domain A HT:  7 6633 2130\n",
      "domain B HT:  13 18866 4955\n",
      "domain C HT:  26 38681 9287\n"
     ]
    }
   ],
   "source": [
    "A_mt = './MultiEnJa/domain_A_mt.tsv'\n",
    "B_mt = './MultiEnJa/domain_B_mt.tsv'\n",
    "C_mt = './MultiEnJa/domain_C_mt.tsv'\n",
    "A_ht = './MultiEnJa/domain_A_ht.tsv'\n",
    "B_ht = './MultiEnJa/domain_B_ht.tsv'\n",
    "C_ht = './MultiEnJa/domain_C_ht.tsv'\n",
    "doc_num, token_sum, type_sum = count(A_mt)\n",
    "print('domain A MT: ', doc_num, token_sum, type_sum)\n",
    "doc_num, token_sum, type_sum = count(B_mt)\n",
    "print('domain B MT: ', doc_num, token_sum, type_sum)\n",
    "doc_num, token_sum, type_sum = count(C_mt)\n",
    "print('domain C MT: ', doc_num, token_sum, type_sum)\n",
    "doc_num, token_sum, type_sum = count(A_ht)\n",
    "print('domain A HT: ', doc_num, token_sum, type_sum)\n",
    "doc_num, token_sum, type_sum = count(B_ht)\n",
    "print('domain B HT: ', doc_num, token_sum, type_sum)\n",
    "doc_num, token_sum, type_sum = count(C_ht)\n",
    "print('domain C HT: ', doc_num, token_sum, type_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文数\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "def count_sent(folder):\n",
    "    sent_num_A = 0\n",
    "    sent_num_B = 0\n",
    "    sent_num_C = 0\n",
    "    for file in os.listdir(folder):\n",
    "        path = folder + '/' + file \n",
    "        file_name = os.path.basename(path)\n",
    "        idx = os.path.splitext(file_name)[0]\n",
    "        nlp = spacy.load(\"ja_ginza\")\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                for sent in nlp(line.strip()).sents:\n",
    "                    if 'A' in idx:\n",
    "                        sent_num_A += 1\n",
    "                    elif 'B' in idx:\n",
    "                        sent_num_B += 1\n",
    "                    else:\n",
    "                        sent_num_C += 1\n",
    "    return sent_num_A, sent_num_B, sent_num_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247 863 2018\n",
      "252 863 2067\n"
     ]
    }
   ],
   "source": [
    "mt_folder = './MultiEnJa/MT-PE/en-ja.mt'\n",
    "ht_folder = './MultiEnJa/human-translation/en-ja.final'\n",
    "sent_num_A_mt, sent_num_B_mt, sent_num_C_mt = count_sent(mt_folder)\n",
    "sent_num_A_ht, sent_num_B_ht, sent_num_C_ht = count_sent(ht_folder)\n",
    "print(sent_num_A_mt, sent_num_B_mt, sent_num_C_mt)\n",
    "print(sent_num_A_ht, sent_num_B_ht, sent_num_C_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考察用のファイルの作成\n",
    "import spacy\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def analysis(input_file, output_file):\n",
    "    url = r\"https?://\\S+\" # URL\n",
    "    email = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\" # メールアドレス\n",
    "\n",
    "    nlp = spacy.load(\"ja_ginza\")\n",
    "    doc_sent = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            for sent in nlp(line.strip()).sents:\n",
    "                sent = str(sent)\n",
    "                sent = re.sub(url, \"URL\", sent)\n",
    "                sent = re.sub(email, \"MAIL\", sent)\n",
    "                doc_sent.append(sent)\n",
    "    with open(output_file, 'w') as g:\n",
    "        header = ['token', 'pos1', 'pos2', 'pos3']\n",
    "        writer = csv.writer(g, delimiter=\"\\t\")\n",
    "        writer.writerow(header)\n",
    "        for i, sent in enumerate(doc_sent):\n",
    "            for j, token in enumerate(nlp(sent)):\n",
    "                ja_pos = token.tag_.split('-')\n",
    "                if len(ja_pos) == 1:\n",
    "                    pos1, pos2, pos3 = str(ja_pos[0]), 'N', 'N'\n",
    "                elif len(ja_pos) == 2:\n",
    "                    pos1, pos2, pos3 = str(ja_pos[0]), str(ja_pos[1]), 'N'\n",
    "                else: # len(ja_pos) == 3:\n",
    "                    pos1, pos2, pos3 = str(ja_pos[0]), str(ja_pos[1]), str(ja_pos[2])\n",
    "                data = [str(token), pos1, pos2, pos3]\n",
    "                writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_A_mt_morphs = './MultiEnJa/domain_A_mt_morphs'\n",
    "domain_A_ht_morphs = './MultiEnJa/domain_A_ht_morphs'\n",
    "domain_B_mt_morphs = './MultiEnJa/domain_B_mt_morphs'\n",
    "domain_B_ht_morphs = './MultiEnJa/domain_B_ht_morphs'\n",
    "domain_C_mt_morphs = './MultiEnJa/domain_C_mt_morphs'\n",
    "domain_C_ht_morphs = './MultiEnJa/domain_C_ht_morphs'\n",
    "mt_folder = './MultiEnJa/MT-PE/en-ja.mt'\n",
    "ht_folder = './MultiEnJa/human-translation/en-ja.final'\n",
    "\n",
    "for file in os.listdir(mt_folder):\n",
    "    mt_path = mt_folder + '/' + file \n",
    "    file_name = os.path.basename(mt_path)\n",
    "    idx = os.path.splitext(file_name)[0]\n",
    "    if 'A' in idx:\n",
    "        output_file = domain_A_mt_morphs + '/' + idx + '.tsv'\n",
    "        analysis(mt_path, output_file)\n",
    "    elif 'B' in idx:\n",
    "        output_file = domain_B_mt_morphs + '/' + idx + '.tsv'\n",
    "        analysis(mt_path, output_file)\n",
    "    else:\n",
    "        output_file = domain_C_mt_morphs + '/' + idx + '.tsv'\n",
    "        analysis(mt_path, output_file)\n",
    "\n",
    "for file in os.listdir(ht_folder):\n",
    "    ht_path = ht_folder + '/' + file \n",
    "    file_name = os.path.basename(ht_path)\n",
    "    idx = os.path.splitext(file_name)[0]\n",
    "    if 'A' in idx:\n",
    "        output_file = domain_A_ht_morphs + '/' + idx + '.tsv'\n",
    "        analysis(ht_path, output_file)\n",
    "    elif 'B' in idx:\n",
    "        output_file = domain_B_ht_morphs + '/' + idx + '.tsv'\n",
    "        analysis(ht_path, output_file)\n",
    "    else:\n",
    "        output_file = domain_C_ht_morphs + '/' + idx + '.tsv'\n",
    "        analysis(ht_path, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
